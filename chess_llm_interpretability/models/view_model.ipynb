{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['model', 'optimizer', 'model_args', 'iter_num', 'best_val_loss', 'best_train_loss', 'config'])\n",
      "model_args {'n_layer': 8, 'n_head': 8, 'n_embd': 512, 'block_size': 399, 'bias': False, 'vocab_size': 17, 'dropout': 0.0}\n",
      "iter_num 22000\n",
      "best_val_loss tensor(0.3845)\n",
      "best_train_loss tensor(0.0268)\n",
      "config {'DATA_PATH': 'data/checkers_games/', 'MODEL_NAME': 'CheckersHuman.pt', 'META_PATH': 'meta.pkl', 'EXPERIMENT_CKPT_DIR': 'data/checkers_games/experiments', 'out_dir': 'out-shakespeare-char', 'eval_interval': 1000, 'log_interval': 50, 'eval_iters': 100, 'eval_only': False, 'always_save_checkpoint': True, 'init_from': 'scratch', 'wandb_log': False, 'wandb_project': 'Checkers', 'wandb_run_name': '8layer', 'dataset': 'openwebtext', 'gradient_accumulation_steps': 4, 'batch_size': 100, 'block_size': 399, 'n_layer': 8, 'n_head': 8, 'n_embd': 512, 'dropout': 0.0, 'bias': False, 'learning_rate': 0.0003, 'max_iters': 600000, 'weight_decay': 0.1, 'beta1': 0.9, 'beta2': 0.95, 'grad_clip': 1.0, 'decay_lr': True, 'warmup_iters': 2000, 'lr_decay_iters': 600000, 'min_lr': 3e-05, 'backend': 'nccl', 'device': 'cuda', 'dtype': 'bfloat16', 'compile': True}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "with open(f'CheckersHuman.pt', 'rb') as f:\n",
    "    state_dict = torch.load(f, map_location=torch.device('cpu'))\n",
    "    print(state_dict.keys())\n",
    "    for key in state_dict.keys():\n",
    "        if key != \"model\" and key != \"optimizer\":\n",
    "            print(key, state_dict[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'vocab_size': 17, 'itos': {0: '\\n', 1: ' ', 2: '-', 3: '.', 4: '/', 5: '0', 6: '1', 7: '2', 8: '3', 9: '4', 10: '5', 11: '6', 12: '7', 13: '8', 14: '9', 15: ';', 16: 'x'}, 'stoi': {'\\n': 0, ' ': 1, '-': 2, '.': 3, '/': 4, '0': 5, '1': 6, '2': 7, '3': 8, '4': 9, '5': 10, '6': 11, '7': 12, '8': 13, '9': 14, ';': 15, 'x': 16}}\n",
      "[15, 6, 3, 1, 6, 6, 2, 6, 10, 1, 7, 9, 2, 7, 5, 1, 7, 3, 1, 13, 2, 6, 6, 1, 7, 13, 2, 7, 9, 1, 8, 3, 1, 14, 2, 6, 8, 1, 7, 7, 2, 6, 13, 1, 9, 3, 1, 6, 10, 16, 7, 7, 1, 7, 10, 16, 6, 13, 1, 10, 3, 1, 9, 2, 13, 1, 7, 11, 2, 7, 7, 1, 11, 3, 1, 6, 5, 2, 6, 9, 1, 6, 13, 16, 14, 1, 12, 3, 1, 10, 16, 6, 9, 1, 7, 7, 2, 6, 13, 1, 13, 3, 1, 6, 2, 10, 1, 6, 13, 16, 14, 1, 14, 3, 1, 10, 16, 6, 9, 1, 7, 14, 2, 7, 10, 1, 6, 5, 3, 1, 6, 6, 2, 6, 10, 1, 7, 9, 2, 6, 14, 1, 6, 6, 3, 1, 6, 10, 16, 7, 9, 1, 7, 10, 2, 7, 7, 1, 6, 7, 3, 1, 7, 9, 2, 7, 13, 1, 7, 7, 2, 6, 13, 1, 6, 8, 3, 1, 11, 2, 14, 1, 7, 12, 2, 7, 9, 1, 6, 9, 3, 1, 13, 2, 6, 6, 1, 7, 9, 2, 6, 14, 1, 6, 10, 3, 1, 12, 2, 6, 5, 1, 7, 5, 2, 6, 11, 1, 6, 11, 3, 1, 6, 6, 16, 7, 5, 1, 6, 13, 2, 6, 10, 1, 6, 12, 3, 1, 7, 2, 11, 1, 6, 10, 2, 6, 6, 1, 6, 13, 3, 1, 6, 7, 2, 6, 11, 1, 6, 14, 16, 6, 7, 1, 6, 14, 3, 1, 6, 5, 2, 6, 10, 1, 6, 6, 2, 13, 1, 7, 5, 3, 1, 6, 10, 2, 6, 13, 1, 7, 6, 2, 6, 12, 1, 7, 6, 3, 1, 6, 8, 16, 7, 7, 1, 8, 5, 2, 7, 11, 1, 7, 7, 3, 1, 6, 13, 16, 7, 12, 1, 7, 11, 16, 6, 12, 16, 6, 5, 16, 6, 1, 5, 2, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      ";1. 11-15 \n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "# meta is used to encode the string pgn strings into integer sequences\n",
    "with open(\"meta.pkl\", \"rb\") as f:\n",
    "    meta = pickle.load(f)\n",
    "\n",
    "print(meta)\n",
    "\n",
    "stoi, itos = meta[\"stoi\"], meta[\"itos\"]\n",
    "encode = lambda s: [stoi[c] for c in s]\n",
    "decode = lambda l: \"\".join([itos[i] for i in l])\n",
    "\n",
    "print(encode(\";1. 11-15 24-20 2. 8-11 28-24 3. 9-13 22-18 4. 15x22 25x18 5. 4-8 26-22 6. 10-14 18x9 7. 5x14 22-18 8. 1-5 18x9 9. 5x14 29-25 10. 11-15 24-19 11. 15x24 25-22 12. 24-28 22-18 13. 6-9 27-24 14. 8-11 24-19 15. 7-10 20-16 16. 11x20 18-15 17. 2-6 15-11 18. 12-16 19x12 19. 10-15 11-8 20. 15-18 21-17 21. 13x22 30-26 22. 18x27 26x17x10x1 0-1                                                                 \"))\n",
    "print(decode(encode(\";1. 11-15 \")))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "othello",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
